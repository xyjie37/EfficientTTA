## Optimization Objectives
Methods that optimize based on unsupervised objectives constitute a classical category of Test-Time Adaptation(TTA) algorithms. These approaches are implemented through minimizing predictive uncertainty, adapting batch statistics, or leveraging density estimation, and are characterized by their reliance on label-free objective functions derived from model outputs or data distributions to align the model with the target domain without supervised signals. In subsequent discussions, we will systematically introduce unsupervised optimization-based Test-Time Adaptation(TTA) algorithms according to their different methodological approaches and analyze whether they are edge-friendly.
### entropy minimization
The essence of entropy-minimization Test-Time Adaptation (TTA) is to take information uncertainty as the optimization signal and realize model self-calibration under the test data distribution through source-free domain online optimization.  
- `DSI`[CoRR'2019]**Dynamic Scale Inference by Entropy Minimization**[[paper](https://arxiv.org/pdf/1908.03182)][[G-Scholar](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Dynamic+Scale+Inference+by+Entropy+Minimization&btnG=)]            
DSI is a Test-Time Adaptation(TTA) algorithm designed to optimize the trade-off between accuracy and computational efficiency by dynamically selecting the model’s input scale. It employs prediction entropy as a confidence measure. Starting from the lowest resolution, the method incrementally scales the input. At each scale, the classification entropy is computed; if it drops below a set threshold, the current prediction is output and the inference is halted, thus avoiding the computational cost of processing higher resolutions.   
Edge-friendly&nbsp;✅   
DSI introduces a multi-resolution inference mechanism and an entropy-based early stopping mechanism. On the ImageNet dataset, it achieves a reduction of approximately 30% in average FLOPs at the cost of only a 0.1% drop in accuracy.
- `Tent`[ICLR'2021]**Tent: Fully Test-time Adaptation by Entropy Minimization**[[paper](https://arxiv.org/abs/2006.10726)][[G-Scholar](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Tent%3A+Fully+Test-time+Adaptation+by+Entropy+Minimization&btnG=)][[code](https://github.com/DequanWang/tent)]  
Tent is a Test-Time Adaptation(TTA) method that operates exclusively on the model and the current unlabeled test data. Its core principle is to minimize the Shannon entropy of the model’s predictions. This process dynamically tunes the affine parameters of the normalization layers, which in turn improves the model’s generalization performance under distribution shift.  
Edge-friendly&nbsp;✅   
Tent achieves its update in merely one forward and one backward pass, restricting optimization to the affine parameters of the normalization layers.
- `EATA`[ICML'2022]**Efficient Test-Time Model Adaptation without Forgetting**[[paper](https://proceedings.mlr.press/v162/niu22a.html)][[G-Scholar](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Efficient+Test-Time+Model+Adaptation+without+Forgetting&btnG=)][[code](https://github.com/mr-eggplant/EATA)]   
EATA is a test-time adaptation method that selectively updates a refined sample subset. It employs a dual-filtering mechanism, based on entropy and diversity weights, to exclude unreliable and redundant samples. On this filtered subset, it performs entropy minimization via backpropagation, while a Fisher regularization term is concurrently applied to mitigate forgetting of in-distribution data during continual adaptation.  
Edge-friendly&nbsp;✅  
By selectively backpropagating through a filtered subset of samples and exclusively updating the affine parameters in its BN layers, EATA reduces inference time by 10% relative to Tent on ImageNet-C.
- `MEMO`[NeurIPS'2022]**MEMO: Test Time Robustness via Adaptation and Augmentation**[[paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/fc28053a08f59fccb48b11f2e31e81c7-Paper-Conference.pdf)][[G-Scholar](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=MEMO%3A+Test+Time+Robustness+via+Adaptation+and+Augmentation&btnG=)][[code](https://github.com/zhangmarvin/memo)]   
MEMO is a Test-Time Adaptation(TTA) algorithm that minimizes the entropy of the marginal predictive distribution over multiple augmented views. The algorithm generates multiple augmented samples from an input, computes their marginal predictive distribution, and optimizes the model parameters to minimize the entropy of this distribution. It then uses the updated model to predict on the original input sample, thereby reducing the impact of non-semantic perturbations.   
Edge-friendly&nbsp;🔶   
MEMO enables single-sample adaptation, making it suitable for edge-based streaming scenarios. However, its update of all model parameters, compared to updating only the Batch Normalization (BN) affine parameters, incurs higher computational costs.
- `SAR`[ICLR'2023] **Towards Stable Test-Time Adaptation in Dynamic Wild World**[[paper](https://openreview.net/pdf?id=g2YraF75Tj)][[G-Scholar](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=TOWARDS+STABLE+TEST-TIME+ADAPTATION+INDYNAMIC+WILD+WORLD&btnG=)][[code](https://github.com/mr-eggplant/SAR)]   
SAR is a Test-Time Adaptation(TTA) algorithm that integrates Reliable Sample Filtering, Sharpness-Aware Minimization, and a Model Recovery Scheme. The algorithm performs model updates exclusively on low-entropy samples and minimizes the worst-case entropy within a neighborhood to avoid converging to sharp minima. To prevent model collapse due to accumulated erroneous updates, SAR maintains a moving average of entropy and rolls back the model when this metric drops anomalously low.   
Edge-friendly&nbsp;🔶   
SAR does not address optimizations for computational efficiency. Its support for online updates and the characteristic of updating only affine transformation parameters make it suitable for edge deployment. However, its Sharpness-Aware Minimization introduces greater computational overhead compared to algorithms such as Tent.
- `UniEnt`[CVPR'2024] **Unified Entropy Optimization for Open-Set Test-Time Adaptation**[[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Gao_Unified_Entropy_Optimization_for_Open-Set_Test-Time_Adaptation_CVPR_2024_paper.pdf)][[G-Scholar](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Unified+Entropy+Optimization+for+Open-Set+Test-Time+Adaptation&btnG=)][[code](https://github.com/gaozhengqing/UniEnt)]
UniEnt is a Test-Time Adaptation(TTA) algorithm that performs entropy minimization and maximization on filtered samples respectively. The algorithm introduces a Distribution-Aware Filter to distinguish whether samples belong to known or unknown classes. UniEnt applies entropy minimization to known class (csID) samples to improve model classification accuracy, and entropy maximization to unknown class (csOOD) samples to reduce the impact of model overconfidence.   
Edge-friendly&nbsp;🔶   
UniEnt focuses more on robustness issues. The algorithm only updates the model's BN affine parameters, making it relatively lightweight. However, it additionally introduces a Distribution-Aware Filter and applies entropy minimization and maximization to samples respectively, resulting in increased computational overhead compared to Tent.
- `CETA`[KDD'2024] **Towards Test Time Adaptation via Calibrated Entropy Minimization**[[paper](https://dl.acm.org/doi/abs/10.1145/3637528.3671672?casa_token=REFEvs1wo2YAAAAA:x6mQ_bHG2MIY0buTx-yluLi1ANP0GDVOoFcNI_hfZfn_RBZPof1LbJdQz7UM45lU2NOEqEj7O0WWwA)][[G-Scholar](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Towards+Test+Time+Adaptation+via+Calibrated+Entropy+Minimization&btnG=)]   
CETA is a Test-Time Adaptation(TTA) algorithm that introduces confidence calibration through entropy minimization. It proposes a calibrated entropy loss that augments the standard entropy with a sample-level regularization term. This term adaptively adjusts the intensity of entropy minimization by leveraging the difference between the Top-1 and Top-2 predicted probabilities, thereby preventing the model from becoming overconfident.     
Edge-friendly&nbsp;🔶   
CETA prioritizes model calibration over computational efficiency. However, its suitability for online scenarios and the characteristic of updating only affine parameters make it promising for edge deployment. Overall, the algorithm introduces only minimal computational overhead compared to Tent.
- `REALM`[WACV'2024]**REALM: Robust Entropy Adaptive Loss Minimization for Improved Single-Sample Test-Time Adaptation**[[paper](https://openaccess.thecvf.com/content/WACV2024/papers/Seto_REALM_Robust_Entropy_Adaptive_Loss_Minimization_for_Improved_Single-Sample_Test-Time_WACV_2024_paper.pdf)][[G-Scholar](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=REALM%3A+Robust+Entropy+Adaptive+Loss+Minimization+for+Improved+Single-Sample+Test-Time+Adaptation&btnG=)]      
REALM introduces a general robust loss function that adaptively adjusts the contribution of each sample’s entropy to the total loss. Rather than coarsely discarding outlier samples, the algorithm intelligently reduces their influence. The loss function in REALM is learnable, and during optimization, gradients are computed simultaneously with respect to the model parameters, shape parameters, and scale parameters, ensuring robust and adaptive performance.     
Edge-friendly&nbsp;🔶     
The core advantage of REALM lies in its robustness, as the algorithm is not specifically optimized for computational efficiency. REALM supports online scenarios and introduces an acceptable computational overhead compared to Tent, making it viable for edge-deployed applications where high stability is required.
- `MoTTA`[AAAI'2025]**Test-Time Adaptation on Noisy Data via Model-Pruning-Based Filtering and Flatness-Aware Entropy Minimization**[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/33179)][[G-Scholar](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=Test-Time+Adaptation+on+Noisy+Data+via+Model-Pruning-Based+Filtering+and+Flatness-Aware+Entropy+Minimization&btnG=)][[code](https://github.com/XingzhiZhou/MoTTA)]   
MoTTA introduces ODP-based Filtering and Flatness-Aware Entropy Minimization to enhance the robustness of Test-Time Adaptation(TTA) under noisy data. The algorithm places samples, filtered by confidence and by output discrepancies between the original and pruned models, into a buffer. It then updates model parameters through entropy minimization using these buffered samples. Concurrently, it reduces noise impact by incorporating both zero-order and first-order flatness constraints, efficiently solving the optimization via first-order Taylor approximation.   
Edge-friendly&nbsp;❌   
MoTTA's noise filtering mechanism relies on a pruned model, and its model parameter update process incorporates a more complex optimization objective. Although the algorithm utilizes Taylor expansion approximation for solving, it still introduces additional gradient computation steps, leading to significantly increased computational overhead compared to Tent.
- `COME`[ICLR'2025]**COME: Test-time Adaption by Conservatively Minimizing Entropy**[[paper](https://openreview.net/pdf?id=506BjJ1ziZ)][[G-Scholar](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C5&q=COME%3A+TEST-TIME+ADAPTION+BY+CONSERVATIVELYMINIMIZING+ENTROPY&btnG=)][[code](https://github.com/BlueWhaleLab/COME)]\
COME is a Test-Time Adaptation(TTA) algorithm that minimizes entropy while explicitly modeling and regularizing predictive uncertainty. It treats classifier outputs as evidence and models predictive uncertainty through Subjective Logic combined with a Dirichlet distribution, thereby constructing Subjective Opinions. COME minimizes the entropy of these subjective opinions to prevent model overconfidence, and integrates unsupervised uncertainty regularization to avoid excessive deviation from the uncertainty characteristics of the pretrained model.\
Edge-friendly&nbsp;✅\
COME is fully adapted to online scenarios. It employs lightweight uncertainty modeling by converting the minimization of subjective opinion entropy into an unconstrained optimization problem. The algorithm's runtime is comparable to that of traditional entropy minimization alone, making it suitable for deployment on edge devices.






